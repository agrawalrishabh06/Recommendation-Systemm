# -*- coding: utf-8 -*-
"""542-DataClean.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r6CXkoMT81CMQYWy4rYfB-GMh-03OKIM
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
!pip install pingouin
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler

missing_values=["N/a","na",np.nan,"N/A"]  
df = pd.read_csv("/content/drive/MyDrive/UIUC_proA/jester_data_5000.csv",na_values=missing_values,low_memory=False)
df.head() 
import pingouin as pg

#/content/drive/MyDrive/UIUC_proA/jester_data_NaN.csv
#/content/drive/MyDrive/UIUC_proA/MarData/mv_data_mean.csv

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

# Commented out IPython magic to ensure Python compatibility.
from scipy.stats import iqr
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder 
# %matplotlib inline
import warnings
import seaborn as sns
warnings.filterwarnings('ignore')
#import the necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score,confusion_matrix, classification_report,roc_auc_score
from scipy.stats import zscore
from sklearn.model_selection import train_test_split

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)

df_scaled.replace(0, np.nan, inplace=True)

df_scaled.fillna(0, inplace=True)

df = df.dropna()

df_scaled.shape

df.shape

df.fillna(df.mean(), inplace=True)

df.head()

from google.colab import files
import pandas as pd

# Save the dataset to a CSV file
df_scaled.to_csv('jester_data_NaN.csv', index=False)

# Download the CSV file to your local machine
files.download('jester_data_NaN.csv')





df.isnull().sum()

from sklearn.preprocessing import MinMaxScaler


scaler = MinMaxScaler(feature_range=(0, 5))


df_scaled = scaler.fit_transform(df)


df_scaled = pd.DataFrame(df_scaled, columns=df.columns)

scaler = MinMaxScaler()

df_scaled = scaler.fit_transform(df.to_numpy())

#df_scaled = pd.DataFrame(df_scaled)
df_scaled.head()

from google.colab import files
import pandas as pd

# Save the dataset to a CSV file
df_scaled.to_csv('jester_data_modified_5000.csv', index=False)

# Download the CSV file to your local machine
files.download('jester_data_modified_5000.csv')

import numpy as np
from scipy.linalg import svd

# Create a sample matrix with missing values
np.random.seed(123)
matrix_missing = np.random.normal(size=(10, 5))
indices = np.random.choice(50, 10, replace=False)
row_indices, col_indices = np.unravel_index(indices, matrix_missing.shape)
matrix_missing[row_indices, col_indices] = np.nan

# Remove NaN values
matrix_missing = np.nan_to_num(matrix_missing)

# Specify the rank for the completed matrix
rank = 3

# Impute missing values using SVD and hard thresholding
u, s, vh = svd(matrix_missing, full_matrices=False)
s[rank:] = 0
matrix_imputed = np.dot(u, np.dot(np.diag(s), vh))

# Generate a true matrix with the same dimensions as matrix_missing
matrix_true = np.random.normal(size=(10, 5))

# Compute the MSE between the true and imputed values
mse = np.mean((matrix_true - matrix_imputed)**2)

# Print the completed matrix and MSE
print(matrix_imputed)
print("MSE:", mse)

import numpy as np
from scipy.linalg import svd

# Set random seed for reproducibility
np.random.seed(123)

# Generate random data with shape (5000, n)
n = 5
data = np.random.normal(size=(5000, n))

# Add missing values to the data
indices = np.random.choice(5000, 500, replace=False)
row_indices, col_indices = np.unravel_index(indices, data.shape)
data[row_indices, col_indices] = np.nan

# Specify the rank for the completed matrix
rank = 3

# Impute missing values using SVD and hard thresholding
u, s, vh = svd(data, full_matrices=False)
s[rank:] = 0
imputed_data = np.dot(u, np.dot(np.diag(s), vh))

# Generate a true matrix with the same dimensions as data
true_data = np.random.normal(size=(5000, n))

# Compute the MSE between the true and imputed values
mse = np.mean((true_data - imputed_data)**2)

# Print the completed matrix and MSE
print(imputed_data)
print("MSE:", mse)

def corrFilter(x: pd.DataFrame, bound: float):
    xCorr = x.corr()
    xFiltered = xCorr[((xCorr >= bound) | (xCorr <= -bound)) & (xCorr !=1.000)]
    xFlattened = xFiltered.unstack().sort_values().drop_duplicates()
    return xFlattened

corrFilter(df_scaled,.1)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Example dataset (rows represent samples, columns represent features)
data = df_scaled
# Standardize the data
scaler = StandardScaler()
data_standardized = df_scaled

# Apply PCA to find all components
pca = PCA()
pca.fit(data_standardized)

# Calculate explained variance ratio
explained_variance_ratio = pca.explained_variance_ratio_

# Plot the explained variance ratio
plt.figure(figsize=(8, 4))
plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.5, align='center', label='Individual explained variance')
plt.step(range(1, len(explained_variance_ratio) + 1), np.cumsum(explained_variance_ratio), where='mid', label='Cumulative explained variance')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal components')
plt.legend(loc='best')
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.ensemble import RandomForestRegressor

# Generate a sample dataset
X, y = make_regression(n_samples=100, n_features=10, n_informative=5, noise=0.1, random_state=42)

# Fit the Random Forest Regression model
regressor = RandomForestRegressor(n_estimators=100, random_state=42)
regressor.fit(X, y)

# Get feature importances
feature_importances = regressor.feature_importances_

# Plot feature importances
plt.figure(figsize=(10, 5))
plt.bar(range(X.shape[1]), feature_importances, align='center')
plt.xticks(range(X.shape[1]))
plt.xlabel('Feature index')
plt.ylabel('Feature importance')
plt.title('Feature importances from Random Forest Regression')
plt.show()



import numpy as np
import pandas as pd
from fancyimpute import SoftImpute
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Load data and normalize


missing_values=["N/a","na",np.nan,"N/A"]  
df = pd.read_csv("/content/jester_data.csv",na_values=missing_values,low_memory=False)
df.head() 

data_matrix = data.to_numpy(dtype=float)
matrix_mean = np.nanmean(data_matrix)
normalized_data_matrix = data_matrix - matrix_mean

# Introduce missing values
np.random.seed(42)
missing_locations = np.random.choice(np.arange(normalized_data_matrix.size), size=10, replace=False)
normalized_data_matrix[np.unravel_index(missing_locations, normalized_data_matrix.shape)] = np.nan

# Split data into training and test sets
train_set, test_set = train_test_split(normalized_data_matrix, test_size=0.2, random_state=42)

# Define custom function for MSE calculation
def mse_soft_impute(data, rank_max, lambda_):
    soft_imputer = SoftImpute(max_rank=rank_max, shrinkage_value=lambda_, verbose=False)
    imputed_data = soft_imputer.fit_transform(data)
    
    mse = mean_squared_error(data[~np.isnan(data)], imputed_data[~np.isnan(data)])
    return mse

# Define parameter grid
rank_max_grid = range(1, 11)
lambda_grid = np.arange(0.1, 1.1, 0.1)
param_grid = [(rank, lambda_) for rank in rank_max_grid for lambda_ in lambda_grid]

# Perform cross-validation
mse_results = []
for rank_max, lambda_ in param_grid:
    imputed_train_set = train_set.copy()
    imputed_train_set[np.isnan(train_set)] = mse_soft_impute(train_set, rank_max, lambda_)
    
    imputed_test_set = test_set.copy()
    imputed_test_set[np.isnan(test_set)] = imputed_train_set[np.isnan(test_set)]
    
    mse = mean_squared_error(test_set[~np.isnan(test_set)], imputed_test_set[~np.isnan(test_set)])
    mse_results.append(mse)

# Find optimal parameters
best_rank_max, best_lambda = param_grid[np.argmin(mse_results)]
print(f"Optimal parameters: max_rank={best_rank_max}, lambda={best_lambda}")

# Perform SoftImpute using optimal parameters
optimal_soft_imputer = SoftImpute(max_rank=best_rank_max, shrinkage_value=best_lambda, verbose=True)
reconstructed_matrix = optimal_soft_imputer.fit_transform(normalized_data_matrix)

import numpy as np
import pandas as pd
from fancyimpute import SoftImpute
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Load data and normalize
data = pd.read_csv('jester_data.csv')
data_matrix = data.to_numpy(dtype=float)
matrix_mean = np.nanmean(data_matrix)
normalized_data_matrix = data_matrix - matrix_mean

# Introduce missing values
np.random.seed(42)
missing_locations = np.random.choice(np.arange(normalized_data_matrix.size), size=10, replace=False)
normalized_data_matrix[np.unravel_index(missing_locations, normalized_data_matrix.shape)] = np.nan

# Split data into training and test sets
indices = np.arange(normalized_data_matrix.shape[0])
train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)

train_set = normalized_data_matrix[train_indices]
test_set = normalized_data_matrix[test_indices]

# Define custom function for MSE calculation
def mse_soft_impute(data, rank_max, lambda_):
    soft_imputer = SoftImpute(max_rank=rank_max, shrinkage_value=lambda_, verbose=False)
    imputed_data = soft_imputer.fit_transform(data)
    
    mse = mean_squared_error(data[~np.isnan(data)], imputed_data[~np.isnan(data)])
    return mse

# Define parameter grid
rank_max_grid = range(1, 11)
lambda_grid = np.arange(0.1, 1.1, 0.1)
param_grid = [(rank, lambda_) for rank in rank_max_grid for lambda_ in lambda_grid]

# Perform cross-validation
mse_results = []
for rank_max, lambda_ in param_grid:
    imputed_train_set = train_set.copy()
    imputed_train_set[np.isnan(train_set)] = mse_soft_impute(train_set, rank_max, lambda_)
    
    imputed_test_set = test_set.copy()
    imputed_test_set[np.isnan(test_set)] = imputed_train_set[np.isnan(test_set)]
    
    mse = mean_squared_error(test_set[~np.isnan(test_set)], imputed_test_set[~np.isnan(test_set)])
    mse_results.append(mse)

# Find optimal parameters
best_rank_max, best_lambda = param_grid[np.argmin(mse_results)]
print(f"Optimal parameters: max_rank={best_rank_max}, lambda={best_lambda}")

# Perform SoftImpute using optimal parameters
optimal_soft_imputer = SoftImpute(max_rank=best_rank_max, shrinkage_value=best_lambda, verbose=True)
reconstructed_matrix = optimal_soft_imputer.fit_transform(normalized_data_matrix)

import numpy as np
import pandas as pd
from fancyimpute import SoftImpute
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Load data and normalize
data = pd.read_csv('jester_data.csv')
data_matrix = data.to_numpy(dtype=float)
matrix_mean = np.nanmean(data_matrix)
normalized_data_matrix = data_matrix - matrix_mean

# Introduce missing values
np.random.seed(42)
missing_locations = np.random.choice(np.arange(normalized_data_matrix.size), size=10, replace=False)
normalized_data_matrix[np.unravel_index(missing_locations, normalized_data_matrix.shape)] = np.nan

# Split data into training and test sets
indices = np.arange(normalized_data_matrix.shape[0])
train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)

train_set = normalized_data_matrix[train_indices]
test_set = normalized_data_matrix[test_indices]

# Define custom function for MSE calculation
def mse_soft_impute(data, rank_max, lambda_):
    soft_imputer = SoftImpute(max_rank=rank_max, shrinkage_value=lambda_, verbose=False)
    imputed_data = soft_imputer.fit_transform(data)
    
    mse = mean_squared_error(data[~np.isnan(data)], imputed_data[~np.isnan(data)])
    return mse

# Define parameter grid
rank_max_grid = range(1, 11)
lambda_grid = np.arange(0.1, 1.1, 0.1)
param_grid = [(rank, lambda_) for rank in rank_max_grid for lambda_ in lambda_grid]

# Perform cross-validation
mse_results = []
for rank_max, lambda_ in param_grid:
    soft_imputer = SoftImpute(max_rank=rank_max, shrinkage_value=lambda_, verbose=False)
    
    imputed_train_set = soft_imputer.fit_transform(train_set)
    imputed_test_set = soft_imputer.transform(test_set)
    
    mse = mean_squared_error(test_set[~np.isnan(test_set)], imputed_test_set[~np.isnan(test_set)])
    mse_results.append(mse)

# Find optimal parameters
best_rank_max, best_lambda = param_grid[np.argmin(mse_results)]
print(f"Optimal parameters: max_rank={best_rank_max}, lambda={best_lambda}")

# Perform SoftImpute using optimal parameters
optimal_soft_imputer = SoftImpute(max_rank=best_rank_max, shrinkage_value=best_lambda, verbose=True)
reconstructed_matrix = optimal_soft_imputer.fit_transform(normalized_data_matrix)

import numpy as np
import pandas as pd
from fancyimpute import SoftImpute
from sklearn.metrics import mean_squared_error

# Load data and normalize

#data = pd.read_csv('jester_data.csv')
data = df
data_matrix = data.to_numpy(dtype=float)
matrix_mean = np.nanmean(data_matrix)
normalized_data_matrix = data_matrix - matrix_mean

# Introduce missing values
np.random.seed(42)
missing_locations = np.random.choice(np.arange(normalized_data_matrix.size), size=10, replace=False)
normalized_data_matrix[np.unravel_index(missing_locations, normalized_data_matrix.shape)] = np.nan

# Define custom function for MSE calculation
def mse_soft_impute(data, rank_max, lambda_):
    soft_imputer = SoftImpute(max_rank=rank_max, shrinkage_value=lambda_, verbose=False)
    imputed_data = soft_imputer.fit_transform(data)
    
    mse = mean_squared_error(data[~np.isnan(data)], imputed_data[~np.isnan(data)])
    return mse

# Define parameter grid
rank_max_grid = range(1, 11)
lambda_grid = np.arange(0.1, 1.1, 0.1)
param_grid = [(rank, lambda_) for rank in rank_max_grid for lambda_ in lambda_grid]

# Perform parameter tuning
mse_results = [mse_soft_impute(normalized_data_matrix, rank_max, lambda_) for rank_max, lambda_ in param_grid]

# Find optimal parameters
best_rank_max, best_lambda = param_grid[np.argmin(mse_results)]
print(f"Optimal parameters: max_rank={best_rank_max}, lambda={best_lambda}")

# Perform SoftImpute using optimal parameters
optimal_soft_imputer = SoftImpute(max_rank=best_rank_max, shrinkage_value=best_lambda, verbose=True)
reconstructed_matrix = optimal_soft_imputer.fit_transform(normalized_data_matrix)

!pip install fancyimpute

### Apply Nerual Matrix Factorization


import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Assuming your user-item matrix is stored in the variable 'data'
data = np.array(df)

# Split the data into train and test sets
X_train, X_test = train_test_split(data, test_size=0.2, random_state=42)

# Define the neural matrix factorization model
num_users, num_items = data.shape
embedding_dim = 64  # Choose the embedding dimension

# Create user embedding matrix
user_input = tf.keras.layers.Input(shape=(1,))
user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)(user_input)
user_vec = tf.keras.layers.Flatten()(user_embedding)

# Create item embedding matrix
item_input = tf.keras.layers.Input(shape=(1,))
item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)(item_input)
item_vec = tf.keras.layers.Flatten()(item_embedding)

# Dot product of user and item embeddings to predict rating
dot_product = tf.keras.layers.Dot(axes=1)([user_vec, item_vec])

neural_mf = tf.keras.Model(inputs=[user_input, item_input], outputs=dot_product)

# Compile the model
neural_mf.compile(optimizer='adam', loss='mse')

# Train the neural matrix factorization model
neural_mf.fit([X_train[:, 0], X_train[:, 1]], X_train[:, 2], epochs=100, batch_size=32, validation_split=0.1)

# Evaluate the model on the test set and calculate MSE
#mse = neural_mf.evaluate([X_test[:, 0], X_test[:, 1]], X_test[:, 2], batch_size=32)
from sklearn.metrics import mean_squared_error

# Obtain the predicted values for the test set
X_test_pred = neural_mf.predict([X_test[:, 0], X_test[:, 1]])

# Calculate the true Mean Squared Error
mse = mean_squared_error(X_test[:, 2], X_test_pred.flatten())
print("Mean Squared Error:", mse)

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Assuming your 5000x100 matrix is stored in the variable 'data'
data = np.array(df)

# Normalize the data (optional, but can improve model performance)
data = data / np.max(data)

# Split the data into train and test sets
X_train, X_test = train_test_split(data, test_size=0.2, random_state=42)

# Define the autoencoder model
input_dim = data.shape[1]
encoding_dim = 64  # Choose the encoding dimension

input_layer = tf.keras.layers.Input(shape=(input_dim,))
encoder = tf.keras.layers.Dense(encoding_dim, activation='relu')(input_layer)
decoder = tf.keras.layers.Dense(input_dim, activation='sigmoid')(encoder)

autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)

# Compile the model
autoencoder.compile(optimizer='adam', loss='mse')

# Train the autoencoder
autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_split=0.1)

# Evaluate the autoencoder on the test set and calculate MSE
#mse = autoencoder.evaluate(X_test, X_test, batch_size=32)
from sklearn.metrics import mean_squared_error

# Obtain the predicted values for the test set
X_test_pred = autoencoder.predict(X_test)

# Calculate the true Mean Squared Error
mse = mean_squared_error(X_test, X_test_pred)
print("Mean Squared Error:", mse)


#print("Mean Squared Error:", mse)

# Print the first 5 rows of the predicted values
print(X_test_pred[:5])

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import mean_squared_error

# Assuming you have a matrix called 'data'
data = df

# Create a mask with random binary values (1s and 0s)
mask = np.random.choice([0, 1], size=data.shape, p=[0.1, 0.9])

# Mask the input data
masked_data = data * mask

# Create a simple feedforward neural network
model = Sequential()
model.add(Dense(256, activation='relu', input_shape=(100,)))
model.add(Dense(128, activation='relu'))
model.add(Dense(100, activation='linear'))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model on the masked data
model.fit(masked_data, data, epochs=100, batch_size=32, verbose=0)

# Predict the complete matrix
predicted_data = model.predict(masked_data)

# Calculate the Mean Squared Error between the original data and the predicted data
mse = mean_squared_error(data, predicted_data)
print(f"Mean Squared Error: {mse}")



## This is correct code


import numpy as np
import pandas as pd
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam

# Create a DataFrame with your data
data = pd.DataFrame(df)
column_names = df.columns
# Replace missing values (NA) with zeros
#data.fillna(0, inplace=True)

# Convert the DataFrame to a NumPy array
data = data.values

# Create a mask with 1s for known values and 0s for unknown values
mask = (data != 0).astype(int)

# Mask the input data
masked_data = data * mask

# Define the neural network architecture
input_layer = Input(shape=(data.shape[1],))
encoded = Dense(50, activation='relu')(input_layer)
encoded1 = Dense(50, activation='relu')(encoded)
encoded2 = Dense(50, activation='relu')(encoded1)
decoded = Dense(data.shape[1], activation='linear')(encoded2)

# Create the autoencoder model
autoencoder = Model(input_layer, decoded)

# Define the learning rate and weight decay
learning_rate = 0.001
weight_decay = 0.01

# Compile the model with custom Adam optimizer
optimizer = Adam(learning_rate=learning_rate, weight_decay=weight_decay)
autoencoder.compile(optimizer=optimizer, loss='mse')

# Train the autoencoder
autoencoder.fit(masked_data, data, epochs=100, batch_size=32)

# Make predictions on the masked data
predictions = autoencoder.predict(masked_data)

# Calculate MSE for the known values
mse = np.mean((mask * (data - predictions))**2)
print("Mean Squared Error:", mse)

# Replace the zeros in the original data with the predicted values
filled_data = data + (1 - mask) * predictions

# Convert the filled data back to a DataFrame
#filled_data_df = pd.DataFrame(filled_data, columns=data.columns)
filled_data_df = pd.DataFrame(filled_data, columns=column_names)

# Save the column names before converting to NumPy array
column_names = df.columns
# Convert the filled data back to a DataFrame
filled_data_df = pd.DataFrame(filled_data, columns=column_names)

filled_data_df



"""From here we will use Movielens dataset"""

# Necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# For matrix factorization
from scipy.sparse.linalg import svds

# Load ratings dataset
rating = pd.read_csv('/content/drive/MyDrive/UIUC_proA/ratings.csv')
rating.head()

rating.isnull().sum()

rating.shape

movie = pd.read_csv('/content/drive/MyDrive/UIUC_proA/movies.csv')
movie.head()

movie.isnull().sum()

movie.shape

# Merge two datasets to have better picture
df = pd.merge(rating, movie, on='movieId')
df.head()

df.isnull().sum()

# Create a dataset to explore
eda_rating = pd.DataFrame(df.groupby('title')['rating'].mean())

# Add number of ratings to the dataset
eda_rating['count of ratings'] = pd.DataFrame(df.groupby('title')['rating'].count())

# This is how it looks like
eda_rating.head()

# Top 10 most rated movies in our dataset
eda_rating.sort_values('count of ratings', ascending=False).head(10)

# Pivot to summarise and count
mtrx_df = rating.pivot(index = 'userId', columns ='movieId', values = 'rating')
#.fillna(0)
mtrx_df.head()

# Demean the data
mtrx = mtrx_df.to_numpy()
#ratings_mean = np.mean(mtrx, axis = 0)
#normalized_mtrx = mtrx - ratings_mean.reshape(-1, 1)

mtrx = mtrx_df.to_numpy()
ratings_mean = np.mean(mtrx, axis=0)  # compute mean rating for each movie
normalized_mtrx = mtrx - ratings_mean  # subtract mean rating for each movie from corresponding ratings

mtrx.shape

from google.colab import files
import pandas as pd

# Save the dataset to a CSV file
mtrx_df.to_csv('mv_data_NaN.csv', index=False)

# Download the CSV file to your local machine
files.download('mv_data_NaN.csv')

dff = pd.DataFrame(normalized_mtrx)



## SVD


data_long = pd.melt(df, id_vars=["ID"], var_name="item", value_name="rating")

from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate

# Create a Surprise dataset from the long format data
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(data_long[["ID", "item", "rating"]], reader)

# Train the SVD model
svd = SVD()

# Perform cross-validation and store the results
results = cross_validate(svd, data, measures=["RMSE"], cv=5)

# Calculate and print the mean RMSE
mean_rmse = np.mean(results['test_rmse'])
print(f"Mean RMSE: {mean_rmse:.4f}")















mtrx_df.shape